login.py: just log-in script -- imported by detail, also provides logged in session
index.py: saves indexes as json files -- not imported, but json files used directly
detail.py: parses json files from index and returns video data using a cache
souschef.py: imports detail, uploads to kolibri
zipscan.py: stand alone: identifies extensions we care about within all zip files.

downloaded: shared and modified docs, audio, videos

TODO:
(done) licencing -- by source json
education tab
continue processing share/modify.json
more filetypes etc.
structure -- nesting etc
(done) collections!
Document only supports pdf not docx



# detail.get_individual_page(item) -- item dict has link, category to handle it
# returns (video_file, subtitle_file) or (file_obj) which are kolibri file objects
# 

# collections.crawl_collection(url) -- returns collection structure:
# title, text, url, resources[], categories[] (each category has the same structure minus categories[])
